1. Відмінності лінійної та логістичної регресії з точки зору вирішеня задачі класифікації.
	Логістична регресія дає на вивід ймовірності (від 0 до 1), лінійна регресія - дійсні числа. 
	У випадку бінарної класифікації для логістичної регресії маємо відносити новий об'єкт до класу 0, якщо вивід моделі <0.5, інакше відносимо об'єкт до класу 1.
	Для лінійної регресії маємо спершу віднайти значення (max-min)/2 (або можливо інший decision boundary), та потім віднести об'єкт до відповідного класу.
	Загалом обидва методи відносяться до лінійних класифікаторів та є досить схожими.
	Зауважу ще переваги логістичної регресії:
		LR model are easy to extend to multi-class classification;
		LR model can be easily be extended to handle non-linear decision boundaries by using kernels or by learning features from data.

2. Обчислити матрицю Грама для ядерної функції k(x) = xsin(x) + x^2 / 5 на множині X = {1, 0, 7, 6, 4, 10}. Аргумент функції sin(x) задано в радіанах.
		Gi,j = K(xi, xj)= k(xi)*k(xj)
		
		
def kernel(x):
    return x*np.sin(x)+(x**2)/5

X = ([1,0,7,6,4,10])

for i in range(6):
    for j in range(6):
        arr[i,j]=kernel(X[i])*kernel(X[j])
		
		array([[  1.08466181,   0.        ,  14.99604301,   5.75257229,
          0.17995579,  15.16359768],
       [  0.        ,   0.        ,   0.        ,   0.        ,
          0.        ,   0.        ],
       [ 14.99604301,   0.        , 207.3284995 ,  79.53245929,
          2.48798727, 209.6450344 ],
       [  5.75257229,   0.        ,  79.53245929,  30.5091297 ,
          0.95440688,  80.42109602],
       [  0.17995579,   0.        ,   2.48798727,   0.95440688,
          0.02985639,   2.5157862 ],
       [ 15.16359768,   0.        , 209.6450344 ,  80.42109602,
          2.5157862 , 211.98745255]])