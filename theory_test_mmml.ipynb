{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_mmml.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkiAkeyjRL3L",
        "colab_type": "text"
      },
      "source": [
        "**1.Класичний та імовірнісний методи головних компонент. Методи отримання головних компонентів**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DC1j97oRJBM",
        "colab_type": "text"
      },
      "source": [
        "Метод головних компонент (МГК) є методом вилучення ознак (feature extraction), а отже, - пониження розмірності даних, які аналізуємо. В цих даних може бути присутнє таке явище як мультиколінеарність, тобто певний прихований зв'язок між змінними. Звідси ж може випливати і надлишковість інформації, яка отримується від них. Тому МГК застосовують, щоб виокремити нові змінні, що є лінійними комбінаціями початкових. В такий спосіб ми можемо зберегти найважливішу інформацію з попереднього пакету даних і при цьому відкинути ту, що найменше пояснює змінність даних.\n",
        "\n",
        "Сам алгоритм полягає у переході до нового ортогонального базису, осі якого вказують на напрямки найбільшої дисперсії даних, вирішенням певної оптимізаційної задачі. І ця задача своя для кожного виду МКГ.\n",
        "\n",
        "Загалом спершу ми припускаємо, що матриця коваріацій між змінними є діагональною зі сталими елементами на діагоналі - дисперсією. Якщо ми говоримо про класичний МКГ, то ці дисперсії прямують до 0 і ми розв'язуємо задачу $||X-WZ^T||_F^2 \\rightarrow 0$, тобто шукаємо такі приховані змінні Z і матрицю змішування W, що комбінація цих змінних перетворюється у наші початкові дані X. У випадку, коли дисперсії>0, то ми застосовуємо ймовірнісний МГК, розв'язуючи оптимізаційну задачу для ймовірностей $log[p(X|W, \\sigma^2)]$.\n",
        "\n",
        "Часто одним із каменів спотикання застосування МГК є неможливість інтерпретації нових змінних."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Z6F5tUTekx",
        "colab_type": "text"
      },
      "source": [
        "**2.Марківські та приховані марківські моделі**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly8jMZvqTk8y",
        "colab_type": "text"
      },
      "source": [
        "Марківські моделі є реалізаціями баєсівських мереж (мереж надійності), в яких виконується марківська властивість: тобто стан поточного вузла залежить від стану лише його батьківських вузлів і не далі (так задається марківський ланцюг 1-порядку; в ланцюзі 2-го ж порядку стан поточного вузла залежатиме від стану двох попередніх вузлів мережі).\n",
        "Одне із найголовніших застосувань марківської моделі - моделювання природної мови, де ми ототожнюємо стани із усіма словами певної мови, і можемо класифікувати тексти, доповнювати речення і т.п."
      ]
    }
  ]
}